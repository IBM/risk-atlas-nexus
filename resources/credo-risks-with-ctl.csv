RISK ID,Risk Type,Risk Scenario,Description,Control ID
RISK-002,AI Agency,"AI pursuing its own goals in conflict with human goals or values (Slattery et al., 2024)","The AI system may act in conflict with ethical standards or human goals or values, especially those of its designers or users, potentially using dangerous capabilities such as manipulation, deception, or situational awareness to seek power, self-proliferate, or achieve other misaligned goals.","['CONTROL-017', 'CONTROL-021', 'CONTROL-022', 'CONTROL-037']"
RISK-003,AI Agency,"AI possessing dangerous capabilities (Slattery et al., 2024)","The AI system may develop, access, or be provided with capabilities that increase its potential to cause mass harm through deception, weapons development and acquisition, persuasion and manipulation, political strategy, cyber-offense, AI development, situational awareness, and self-proliferation.","['CONTROL-021', 'CONTROL-022', 'CONTROL-037']"
RISK-004,Environmental Harm,"Environmental harm (Slattery et al., 2024; IBM, 2024; AI, 2023)", The AI system's development and operation may cause environmental harm through energy consumption of data centers or the materials and carbon footprints associated with AI hardware.,"['CONTROL-032', 'CONTROL-036']"
RISK-005,Explainability & Transparency,"Lack of training data transparency (IBM, 2024)","Without accurate documentation on how a model's data was collected, curated, and used to train a model, it may be harder to satisfactorily explain the behavior of the model with respect to the data. Data provenance issues may also increase legal risks (e.g., intellectual property infringement).",['CONTROL-009']
RISK-006,Explainability & Transparency, Lack of inference data transparency, Lack of inference data transparency: Insufficient visibility into data sources used during model inference,"['CONTROL-010', 'CONTROL-011']"
RISK-007,Explainability & Transparency,"Inadequate observability (Slatteryet al., 2024)","The AI system may lack sufficient logging or traceability features, making it difficult to monitor or audit its decision-making process after the fact.",['CONTROL-010']
RISK-009,Explainability & Transparency,"Black box decisionmaking (Slattery et al., 2024; IBM, 2024)","The AI system's decision-making process may be opaque, even when the architecture is known, making it difficult to understand how the system arrives at its outputs or recommendations.","['CONTROL-011', 'CONTROL-037']"
RISK-010,Fairness & Bias,"Stereotype perpetuation (Slattery et al., 2024; IBM, 2024)","The AI system's outputs may explicitly reflect or reinforce harmful stereotypes, prejudices, or biased characterizations of specific groups. The AI system may exhibit unjustified or harmful differences in accuracy, quality, or outcomes across demographic groups, potentially leading to unfair treatment and discrimination. This includes both disparate error rates that affect opportunity and","['CONTROL-014', 'CONTROL-015', 'CONTROL-016', 'CONTROL-028']"
RISK-012,Fairness & Bias,Unequal access to AI benefits,"The AI system's benefits may not be equally accessible to all users, potentially resulting in reduced advantages for those with limited access. Accessibility may be affected by physical abilities, cognitive abilities, language, or technological access.","['CONTROL-014', 'CONTROL-015', 'CONTROL-016', 'CONTROL-028']"
RISK-013,Harmful Content,"Toxic content (Slattery et al., 2024; IBM, 2024)","The AI system may generate or respond with hateful content, such as racist, sexist, or otherwise offensive material.","['CONTROL-017', 'CONTROL-018', 'CONTROL-019']"
RISK-014,Harmful Content,"Obscene and sexually abusive content (Slattery et al., 2024; AI, 2023)","The AI system may generate or disseminate content that is obscene, degrading, or sexually abusive, including child sexual abuse material (CSAM) or non-consensual intimate images (NCII).","['CONTROL-017', 'CONTROL-018', 'CONTROL-019']"
RISK-015,Harmful Content,"Dangerous or violent content (IBM, 2024)", The AI system may produce content that incites violence or provides instructions for committing crimes.,"['CONTROL-017', 'CONTROL-018', 'CONTROL-019']"
RISK-016,Human-AI Interaction,"Overor under-reliance and unsafe use (Slattery et al., 2024; IBM, 2024; AI, 2023)","Users may inappropriately rely on the AI system for critical decisions or tasks beyond its capabilities, or fail to put trust in AI systems when they should, potentially leading to errors or safety issues.","['CONTROL-009', 'CONTROL-011', 'CONTROL-028', 'CONTROL-029', 'CONTROL-029']"
RISK-017,Human-AI Interaction, Inadequate AI literacy and communication,"The AI system's capabilities, limitations, and appropriate use cases may be insufficiently understood or communicated within the organization, potentially resulting in ineffective implementation or failure to achieve desired outcomes.","['CONTROL-009', 'CONTROL-025']"
RISK-018,Human-AI Interaction, AI deception,"The AI system may misrepresent its own capabilities or limitations, potentially leading to misplaced trust or inappropriate","['CONTROL-010', 'CONTROL-025']"
RISK-026,Malicious Use,"Fraud, scams, and targeted manipulation","The AI system may be exploited to facilitate fraudulent activities, scams, or targeted manipulation, including generating deepfakes and enhancing phishing attacks.","['CONTROL-017', 'CONTROL-018', 'CONTROL-019', 'CONTROL-022', 'CONTROL-023']"
RISK-027,Malicious Use,"Cyberattacks, weapon development, and mass harm (AI, 2023; IBM, 2024)","The AI system may be misused for developing malicious software, lethal autonomous weapons, or planning large-scale harmful activities.","['CONTROL-017', 'CONTROL-018', 'CONTROL-019', 'CONTROL-021', 'CONTROL-022', 'CONTROL-023']"
RISK-028,Malicious Use,"Coordinated influence operations (Slattery et al., 2024; IBM, 2024)", Coordinated influence operations: Large-scale manipulation and disinformation campaigns ,"['CONTROL-021', 'CONTROL-022', 'CONTROL-023']"
RISK-029,Malicious Use,"Mass surveillance and privacy attacks (Slattery et al., 2024)", Mass surveillance and privacy attacks: Unauthorized monitoring and privacy violation at scale,"['CONTROL-021', 'CONTROL-022', 'CONTROL-023']"
RISK-033,Performance & Robustness,"Lack of adequate capabilities (Slattery et al., 2024; IBM, 2024; AI, 2023)","The AI system may fail to achieve required performance levels due to fundamental technological limitations or insufficient resources, potentially leading to suboptimal or unreliable outcomes.","['CONTROL-012', 'CONTROL-016']"
RISK-034,Performance & Robustness, Oversight and evaluation challenges,"The AI system may present difficulties in overseeing or evaluating its models, potentially introducing performance risks in both predeployment assessments and ongoing monitoring.","['CONTROL-010', 'CONTROL-012']"
RISK-035,Performance & Robustness,"Lack of robustness (Slattery et al., 2024)","The AI system's performance may fail to generalize well to new environments or inputs, potentially leading to unexpected failures or degraded performance in real-world applications.","['CONTROL-022', 'CONTROL-028']"
RISK-036,Privacy,"Compromised personally identifiable information (Slattery et al., 2024)","The AI system may expose personally identifiable information (PII), either inadvertently or due to adversarial inputs, derived from training data, accessible data, or inferences. PII is any data that can be used to directly identify or contact a specific individual, either alone or in combination with other information.","['CONTROL-001', 'CONTROL-023', 'CONTROL-026', 'CONTROL-026']"
RISK-037,Privacy,"Compromised sensitive information (Slattery et al., 2024; IBM, 2024; AI, 2023)","The AI system may expose personally sensitive information, either inadvertently or due to adversarial inputs, derived from training data, accessible data, or inferences. Sensitive personal data is information that, while not necessarily identifying an individual, could cause harm, discrimination, or distress to a person if exposed, including details about their health, finances, beliefs, behaviors, relationships, and private life circumstances.","['CONTROL-001', 'CONTROL-026', 'CONTROL-026']"
RISK-042,Societal Impact,"Increased inequality and decline in employment quality (Slattery et al., 2024; IBM, 2024)","The AI system's widespread use may cause social and economic inequalities by automating jobs, reducing employment quality, or producing exploitative dependencies between workers and their employers.",['CONTROL-035']
RISK-043,Societal Impact,"Economic and cultural devaluation of human effort (Slattery et al., 2024; IBM, 2024)","The AI system may create economic or cultural value through reproduction of human innovation or creativity, potentially destabilizing economic and social systems that rely on human effort and leading to reduced appreciation for human skills, disruption of industries, and homogenization of cultural experiences.",['CONTROL-035']
RISK-044,Societal Impact,"Power centralization and unfair distribution of benefits (Slattery et al., 2024)","The AI system may drive concentration of power and resources within certain entities or groups, especially those with access to or ownership of powerful AI systems, potentially leading to inequitable distribution of benefits and increased societal inequality.","['CONTROL-035', 'CONTROL-036']"
RISK-045,Societal Impact,"Competitive dynamics (Slattery et al., 2024)", The AI system's rapid development,['CONTROL-036']
RISK-046,Societal Impact,"Governance failures (Slattery et al., 2024)","The AI system may outpace regulatory frameworks and oversight mechanisms, potentially leading to ineffective governance and the inability to manage AI risks appropriately.","['CONTROL-029', 'CONTROL-036', 'CONTROL-040', 'CONTROL-041', 'CONTROL-042']"