{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### This notebook illustrates how to identify AI tasks based on specific use cases."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "##### Import libraries"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from risk_atlas_nexus.blocks.inference import (\n",
            "    RITSInferenceEngine,\n",
            "    WMLInferenceEngine,\n",
            "    OllamaInferenceEngine,\n",
            "    VLLMInferenceEngine,\n",
            ")\n",
            "from risk_atlas_nexus.blocks.inference.params import (\n",
            "    InferenceEngineCredentials,\n",
            "    RITSInferenceEngineParams,\n",
            "    WMLInferenceEngineParams,\n",
            "    OllamaInferenceEngineParams,\n",
            "    VLLMInferenceEngineParams,\n",
            ")\n",
            "from risk_atlas_nexus.library import RiskAtlasNexus"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "##### Risk Atlas Nexus uses Large Language Models (LLMs) to infer risks dimensions. Therefore requires access to LLMs to inference or call the model. \n",
            "\n",
            "**Available Inference Engines**: WML, Ollama, vLLM, RITS. Please follow the [Inference APIs](https://github.com/IBM/risk-atlas-nexus?tab=readme-ov-file#install-for-inference-apis) guide before going ahead.\n",
            "\n",
            "*Note:* RITS is intended solely for internal IBM use and requires TUNNELALL VPN for access."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "inference_engine = WMLInferenceEngine(\n",
            "    model_name_or_path=\"ibm/granite-20b-code-instruct\",\n",
            "    credentials={\n",
            "        \"api_key\": \"WML_API_KEY\",\n",
            "        \"api_url\": \"WML_API_URL\",\n",
            "        \"project_id\": \"WML_PROJECT_ID\",\n",
            "    },\n",
            "    parameters=WMLInferenceEngineParams(\n",
            "        max_new_tokens=1000, decoding_method=\"greedy\", repetition_penalty=1\n",
            "    ),\n",
            "    postprocessors=[\"list_of_str\"],\n",
            ")\n",
            "\n",
            "# inference_engine = OllamaInferenceEngine(\n",
            "#     model_name_or_path=\"hf.co/ibm-granite/granite-20b-code-instruct-8k-GGUF\",\n",
            "#     credentials=InferenceEngineCredentials(api_url=\"OLLAMA_API_URL\"),\n",
            "#     parameters=OllamaInferenceEngineParams(\n",
            "#         num_predict=1000, num_ctx=8192, temperature=0.7, repeat_penalty=1\n",
            "#     ),\n",
            "#     postprocessors=[\"list_of_str\"],\n",
            "# )\n",
            "\n",
            "# inference_engine = VLLMInferenceEngine(\n",
            "#     model_name_or_path=\"ibm-granite/granite-3.1-8b-instruct\",\n",
            "#     credentials=InferenceEngineCredentials(\n",
            "#         api_url=\"VLLM_API_URL\", api_key=\"VLLM_API_KEY\"\n",
            "#     ),\n",
            "#     parameters=VLLMInferenceEngineParams(max_tokens=1000, temperature=0.7),\n",
            "#     postprocessors=[\"list_of_str\"],\n",
            "# )\n",
            "\n",
            "# inference_engine = RITSInferenceEngine(\n",
            "#     model_name_or_path=\"ibm/granite-20b-code-instruct\",\n",
            "#     credentials={\n",
            "#         \"api_key\": \"RITS_API_KEY\",\n",
            "#         \"api_url\": \"RITS_API_URL\",\n",
            "#     },\n",
            "#     parameters=RITSInferenceEngineParams(max_tokens=1000, temperature=0.7),\n",
            "#     postprocessors=[\"list_of_str\"],\n",
            "# )"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "##### Create an instance of RiskAtlasNexus\n",
            "\n",
            "*Note: (Optional)* You can specify your own directory in `RiskAtlasNexus(base_dir=<PATH>)` to utilize custom AI ontologies. If left blank, the system will use the provided AI ontologies."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "risk_atlas_nexus = RiskAtlasNexus()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "##### AI Tasks Identification API\n",
            "\n",
            "RiskAtlasNexus.identify_ai_tasks_from_usecases()\n",
            "\n",
            "Params:\n",
            "* usecases (List[str]): A List of strings describing AI usecases\n",
            "* inference_engine (InferenceEngine): An LLM inference engine to identify AI tasks from usecases."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "usecase = \"Generate personalized, relevant responses, recommendations, and summaries of claims for customers to support agents to enhance their interactions with customers.\"\n",
            "\n",
            "risks = risk_atlas_nexus.identify_ai_tasks_from_usecases(\n",
            "    usecases=[usecase],\n",
            "    inference_engine=inference_engine,\n",
            ")\n",
            "\n",
            "risks"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "nexus",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.11.4"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
