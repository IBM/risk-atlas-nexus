{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auto-fill Questionnaire using Chain of Thought or Few-Shot Examples\n",
    "\n",
    "This notebook showcases the application of few-shot examples in autofilling questionnaires. It utilizes a json file (`cot_examples.json`) to\n",
    "provide the LLM with example responses for some use-cases.\n",
    "\n",
    "By leveraging these few-shot examples, we can enable seamless completion of lengthy questionnaires, minimizing manual effort and improving overall efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhaval/Projects/Usage-Governance/risk-atlas-nexus/src/risk_atlas_nexus/toolkit/job_utils.py:2: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from risk_atlas_nexus.blocks.inference import (\n",
    "    RITSInferenceEngine,\n",
    "    WMLInferenceEngine,\n",
    "    OllamaInferenceEngine,\n",
    "    VLLMInferenceEngine,\n",
    ")\n",
    "from risk_atlas_nexus.blocks.inference.params import (\n",
    "    InferenceEngineCredentials,\n",
    "    RITSInferenceEngineParams,\n",
    "    WMLInferenceEngineParams,\n",
    "    OllamaInferenceEngineParams,\n",
    "    VLLMInferenceEngineParams,\n",
    ")\n",
    "\n",
    "from risk_atlas_nexus.data import load_resource\n",
    "from risk_atlas_nexus.library import RiskAtlasNexus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk Atlas Nexus uses Large Language Models (LLMs) to infer risks dimensions. Therefore requires access to LLMs to inference or call the model.\n",
    "\n",
    "**Available Inference Engines**: WML, Ollama, vLLM, RITS. Please follow the [Inference APIs](https://github.com/IBM/risk-atlas-nexus?tab=readme-ov-file#install-for-inference-apis) guide before going ahead.\n",
    "\n",
    "_Note:_ RITS is intended solely for internal IBM use and requires TUNNELALL VPN for access.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-25 22:39:41:225] - INFO - RiskAtlasNexus - OLLAMA inference engine will execute requests on the server at http://localhost:11434.\n",
      "[2025-05-25 22:39:41:374] - INFO - RiskAtlasNexus - Created OLLAMA inference engine.\n"
     ]
    }
   ],
   "source": [
    "inference_engine = OllamaInferenceEngine(\n",
    "    model_name_or_path=\"granite3.2:8b\",\n",
    "    credentials=InferenceEngineCredentials(api_url=\"OLLAMA_API_URL\"),\n",
    "    parameters=OllamaInferenceEngineParams(\n",
    "        num_predict=1000, temperature=0, repeat_penalty=1, num_ctx=8192\n",
    "    ),\n",
    ")\n",
    "\n",
    "# inference_engine = WMLInferenceEngine(\n",
    "#     model_name_or_path=\"ibm/granite-20b-code-instruct\",\n",
    "#     credentials={\n",
    "#         \"api_key\": \"WML_API_KEY\",\n",
    "#         \"api_url\": \"WML_API_URL\",\n",
    "#         \"project_id\": \"WML_PROJECT_ID\",\n",
    "#     },\n",
    "#     parameters=WMLInferenceEngineParams(\n",
    "#         max_new_tokens=1000, decoding_method=\"greedy\", repetition_penalty=1\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "# inference_engine = VLLMInferenceEngine(\n",
    "#     model_name_or_path=\"ibm-granite/granite-3.1-8b-instruct\",\n",
    "#     credentials=InferenceEngineCredentials(\n",
    "#         api_url=\"VLLM_API_URL\", api_key=\"VLLM_API_KEY\"\n",
    "#     ),\n",
    "#     parameters=VLLMInferenceEngineParams(max_tokens=1000, temperature=0.7),\n",
    "# )\n",
    "\n",
    "# inference_engine = RITSInferenceEngine(\n",
    "#     model_name_or_path=\"ibm-granite/granite-3.1-8b-instruct\",\n",
    "#     credentials={\n",
    "#         \"api_key\": \"RITS_API_KEY\",\n",
    "#         \"api_url\": \"RITS_API_URL\",\n",
    "#     },\n",
    "#     parameters=RITSInferenceEngineParams(max_tokens=1000, temperature=0.7),\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create an instance of RiskAtlasNexus\n",
    "\n",
    "_Note: (Optional)_ You can specify your own directory in `RiskAtlasNexus(base_dir=<PATH>)` to utilize custom AI ontologies. If left blank, the system will use the provided AI ontologies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-25 22:39:41:446] - INFO - RiskAtlasNexus - Created RiskAtlasNexus instance. Base_dir: None\n"
     ]
    }
   ],
   "source": [
    "risk_atlas_nexus = RiskAtlasNexus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Few-Shot Examples for Auto-Assist Functionality\n",
    "\n",
    "This cell showcases the template used in `risk_atlas_nexus/data/templates/risk_questionnaire_cot.json` to provide few-shot\n",
    "examples for auto-assist functionality.\n",
    "\n",
    "**Template Structure:**\n",
    "\n",
    "- Each question is associated with a list of example intents and\n",
    "  corresponding answers.\n",
    "- The format is:\n",
    "\n",
    "```shell\n",
    "  [\n",
    "      {\n",
    "          \"question\": \"In which environment is the system used?\",\n",
    "          \"examples\": [\n",
    "              \"intent\": \"Find patterns in healthcare insurance claims\",\n",
    "              \"answer\": \"Insurance Claims Processing or Risk Management or Data Analytics\",\n",
    "              \"explanation\": \"The system might be used by an insurance company's claims processing department to analyze and identify patterns in healthcare insurance claims.\"\n",
    "          ]\n",
    "      }\n",
    "  ]\n",
    "```\n",
    "\n",
    "In this notebook, we're using a simplified template to cover 7 questions\n",
    "from the Airo questionnaire:\n",
    "\n",
    "1. AI Domain\n",
    "2. System environment\n",
    "3. Utilized techniques\n",
    "4. Intended User\n",
    "5. Intended Purpose\n",
    "6. System Application\n",
    "7. AI Subject\n",
    "\n",
    "**Customization:**\n",
    "\n",
    "To adapt this auto-assist functionality to custom questionnaires, users\n",
    "need to provide their own set of questions, example intents, and\n",
    "corresponding answers in a json file (e.g., `risk_questionnaire_cot.json`). This will enable\n",
    "the LLM to learn from these few-shot examples and generate responses for\n",
    "unseen queries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Risk Questionnaire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'no': 'Q1',\n",
       "  'text': 'What domain does your use request fall under? Customer service/support, Technical, Information retrieval, Strategy, Code/software engineering, Communications, IT/business automation, Writing assistant, Financial, Talent and Organization including HR, Product, Marketing, Cybersecurity, Healthcare, User Research, Sales, Risk and Compliance, Design, Other'},\n",
       " {'no': 'Q2', 'text': 'In which environment is the system used?'},\n",
       " {'no': 'Q3',\n",
       "  'text': 'What techniques are utilised in the system? Multi-modal: {Document Question/Answering, Image and text to text, Video and text to text, visual question answering}, Natural language processing: {feature extraction, fill mask, question answering, sentence similarity, summarization, table question answering, text classification, text generation, token classification, translation, zero shot classification}, computer vision: {image classification, image segmentation, text to image, object detection}, audio:{audio classification, audio to audio, text to speech}, tabular: {tabular classification, tabular regression}, reinforcement learning.'},\n",
       " {'no': 'Q4', 'text': 'Who is the intended user of the system?'},\n",
       " {'no': 'Q5', 'text': 'What is the intended purpose of the system?'},\n",
       " {'no': 'Q6', 'text': 'What is the application of the system?'},\n",
       " {'no': 'Q7', 'text': 'Who is the subject as per the intent?'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_questionnaire = load_resource(\"risk_questionnaire.json\")\n",
    "risk_questionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to use the inference engine to get the LLM outputs. `generate_zero_shot_risk_questionnaire_output` which gives the zero-shot output for the question and `generate_few_shot_risk_questionnaire_output` which gives the output using few-shot examples defined above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferring with OLLAMA: 100%|██████████| 7/7 [00:26<00:00,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1: Customer service/support\n",
      "\n",
      " 2: The system is used in a digital environment, specifically designed for online interactions between customers and support agents.\n",
      "\n",
      " 3: The system employs a variety of techniques, including multi-modal capabilities such as Document Question/Answering, Image and text to text, Video and text to text, and visual question answering. In terms of Natural Language Processing, it utilizes methods like feature extraction, fill mask, question answering, sentence similarity, summarization, table question answering, text classification, text generation, token classification, translation, and zero shot classification. For computer vision, it uses image classification, image segmentation, text to image, and object detection. It also incorporates audio techniques such as audio classification and text to speech. Additionally, it includes tabular methods like tabular classification and tabular regression. Lastly, it leverages reinforcement learning.\n",
      "\n",
      " 4: The intended user of the system is the support agent.\n",
      "\n",
      " 5: The intended purpose of the system is to assist compliance officers in generating personalized, relevant responses, recommendations, and summaries of claims for customers. This is done to enhance interactions between support agents and customers, ensuring accurate and efficient communication.\n",
      "\n",
      " 6: The application of the system is to assist compliance officers in generating personalized, relevant responses, recommendations, and summaries of claims for support agents. This is achieved by understanding the intent of the customer's inquiry and providing tailored information to enhance the interaction between the support agent and the customer.\n",
      "\n",
      " 7: The subject in this context is the compliance officer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "usecase = \"Generate personalized, relevant responses, recommendations, and summaries of claims for customers to support agents to enhance their interactions with customers.\"\n",
    "\n",
    "results = risk_atlas_nexus.generate_zero_shot_risk_questionnaire_output(\n",
    "    usecase, risk_questionnaire, inference_engine\n",
    ")\n",
    "\n",
    "for index, result in enumerate(results, start=1):\n",
    "    print(f\"\\n {index}: \" + result.prediction[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferring with OLLAMA:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferring with OLLAMA: 100%|██████████| 7/7 [00:43<00:00,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1: Customer service/support\n",
      "\n",
      " 2: Customer Service or Claims Support Departments\n",
      "\n",
      " 3: Natural language processing: text generation and summarization\n",
      "\n",
      " 4: Customer Support Agents\n",
      "\n",
      " 5: To enhance customer service by providing support agents with personalized, contextually relevant information and recommendations, enabling them to address customer inquiries and claims more effectively and efficiently.\n",
      "\n",
      " 6: Natural Language Generation (NLG): Develop AI models to generate personalized, context-aware responses and summaries for customer interactions. \n",
      "Sentiment Analysis: Use NLP to understand customer sentiment and tailor responses accordingly. \n",
      "Recommendation Engine: Analyze customer data to suggest relevant products, services, or solutions based on individual preferences and needs. \n",
      "Chatbot Integration: Integrate with customer support platforms to provide real-time, automated assistance to support agents.\n",
      "\n",
      " 7: Claims and Customers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "usecase = \"Generate personalized, relevant responses, recommendations, and summaries of claims for customers to support agents to enhance their interactions with customers.\"\n",
    "\n",
    "# load CoT examples for risk questionnaire\n",
    "risk_questionnaire_cot = load_resource(\"risk_questionnaire_cot.json\")\n",
    "\n",
    "results = risk_atlas_nexus.generate_few_shot_risk_questionnaire_output(\n",
    "    usecase,\n",
    "    risk_questionnaire_cot,\n",
    "    inference_engine,\n",
    ")\n",
    "\n",
    "for index, result in enumerate(results, start=1):\n",
    "    print(f\"\\n {index}: \" + result.prediction[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nexus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
